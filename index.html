<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="OphNet: A Large-Scale Video Benchmark for Ophthalmic Surgical Workflow Understanding">
  <meta name="keywords" content="OphNet, surgical-workflow-understanding, ophthalmic-surgery">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OphNet: A Large-Scale Video Benchmark for Ophthalmic Surgical Workflow Understanding</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">OphNet: A Large-Scale Video Benchmark for Ophthalmic Surgical Workflow Understanding</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/minghu0830">Ming Hu</a><sup>1,2,3 *</sup>,</span>
            <span class="author-block">
              <a href="https://richard-peng-xia.github.io/">Peng Xia</a><sup>1,3 *</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=A_mtOiMAAAAJ&hl=en">Lin Wang</a><sup>5 *</sup>,</span>
            <span class="author-block">
              <a href="https://siyuanyan1.github.io/">Siyuan Yan</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Z5BHRAYAAAAJ&hl=en">Feilong Tang</a><sup>1,3</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Og0Ewb8AAAAJ&hl=en">Zhongxing Xu</a><sup>7</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=InHF3ykAAAAJ">Yimin Luo</a><sup>6</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=BUF_-N8AAAAJ&hl=en">Kaimin Song</a><sup>3</sup>,</span>   
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=mzZy2NMAAAAJ&hl=en">Jurgen Leitner</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://xueliancheng.github.io/">Xuelian Cheng</a><sup>1</sup>,</span>
              <span class="author-block">
            <span class="author-block">
              <a href="https://samjcheng.github.io/">Jun Cheng</a><sup>8</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=OVA8Q54AAAAJ&hl=en">Chi Liu</a><sup>9</sup>,</span>
            <span class="author-block">
              <a href="">Kaijing Zhou</a><sup>4 †</sup>,</span>
            <span class="author-block">
              <a href="https://zongyuange.github.io/">Zongyuan Ge</a><sup>1,2,3 †</sup></span> 
            </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>AIM Lab, Faculty of IT, Monash University,</span>
            <span class="author-block"><sup>2</sup>Faculty of Engineering, Monash University</span>
            <span class="author-block"><sup>3</sup>Airdoc-Monash Research, Airdoc,</span>
            <span class="author-block"><sup>4</sup>Eye Hospital, Wenzhou Medical University,</span>
            <span class="author-block"><sup>5</sup>Bosch Corporate Research</span>
            <span class="author-block"><sup>6</sup>King's College London,</span>
            <span class="author-block"><sup>7</sup>Cornell University,</span>
            <span class="author-block"><sup>8</sup>Institute for Infocomm Research, A*STAR</span>
            <span class="author-block"><sup>9</sup>Faculty of Data Science, City University of Macau</span>
          </div>

          <div class="is-size-3">
            <span style="color: rgb(165, 165, 165);">ECCV 2024</span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2406.07471"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/minghu0830/OphNet-benchmark"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://forms.gle/GhJyQDPUrE74jLy87"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/images/logo.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">OphNet:</span>the largest video dataset for ophthalmic surgical workflow analysis
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Surgical scene perception via videos is critical for advancing robotic surgery, telesurgery, and AI-assisted surgery, particularly in ophthalmology. However, the scarcity of diverse and richly annotated video datasets has hindered the development of intelligent systems for surgical workflow analysis. Existing datasets face challenges such as small scale, lack of diversity in surgery and phase categories, and absence of time-localized annotations. These limitations impede action understanding and model generalization validation in complex and diverse real-world surgical scenarios. To address this gap, we introduce OphNet, a large-scale, expert-annotated video benchmark for ophthalmic surgical workflow understanding. OphNet features:
          </p>
          <p>
            1) A diverse collection of 2,278 surgical videos spanning 66 types of cataract, glaucoma, and corneal surgeries, with detailed annotations for 102 unique surgical phases and 150 fine-grained operations.
          </p>
          <p>
            2) Sequential and hierarchical annotations for each surgery, phase, and operation, enabling comprehensive understanding and improved interpretability.
          </p> 
          <p>
            3) Time-localized annotations, facilitating temporal localization and prediction tasks within surgical workflows. With approximately 205 hours of surgical videos, OphNet is about 20 times larger than the largest existing surgical workflow analysis benchmark.
          </p>
        </div>
      </div>
    </div>
  </div>

  <div class="container is-max-desktop">
    <!-- Re-rendering. -->
    <div class="column">
      <!-- <h3 class="title is-4">Operation</h3> -->
      <div class="content has-text-justified">
        <p>

        </p>
      </div>
      <div class="content has-text-centered">
        <img id="replay-image" src="./static/images/loca.png" alt="Re-rendering the input video" width="75%">
      </div>
    </div>

    <div class="container is-max-desktop">
      <!-- Re-rendering. -->
      <div class="column">
        <!-- <h3 class="title is-4">Operation</h3> -->
        <div class="content has-text-justified">
          <p>
  
          </p>
        </div>
        <div class="content has-text-centered">
          <img id="replay-image" src="./static/images/sta.png" alt="Re-rendering the input video" width="75%">
        </div>
      </div>

</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="column">
      <h3 class="title is-4">Challenge/Workshop</h3>
      <div class="content has-text-justified">
        <p>
          Coming soon...
        </p>
      </div>
      <!-- <div class="content has-text-centered"> -->
        <!-- <img id="replay-image" src="./static/images/2.jpg" alt="Re-rendering the input video" width="75%"> -->
      <!-- </div> -->
    </div>
    </div>



<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="column">
      <h3 class="title is-4">Operation</h3>
      <div class="content has-text-justified">
        <p>
          xxxx
        </p>
      </div>
      <div class="content has-text-centered">
        <img id="replay-image" src="./static/images/2.jpg" alt="Re-rendering the input video" width="75%">
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Phase</h2>
          <p>
           xxx
          </p>
          <img id="dollyzoom" src="./static/images/2.jpg" alt="Dolly Zoom" height="100%">
        </div>
      </div>

      <div class="column">
        <h2 class="title is-4">Surgery</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              xxx
            </p>
            <img id="matting-image" src="./static/images/3.png" alt="Matting" height="100%">
          </div>
        </div>
      </div>
    </div> -->




    
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{hu2024ophnet,
@article{hu2024ophnet,
  title={OphNet: A Large-Scale Video Benchmark for Ophthalmic Surgical Workflow Understanding},
  author={Hu, Ming and Xia, Peng and Wang, Lin and Yan, Siyuan and Tang, Feilong and Xu, Zhongxing and Luo, Yimin and Song, Kaimin and Leitner, Jurgen and Cheng, Xuelian and others},
  journal={arXiv preprint arXiv:2406.07471},
  year={2024}
}</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is developed based on <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies.</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
